{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuOUsxwam8ZTFQj2DI2Cc2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadhamashraf/ZC-SP24-DSAI-201/blob/main/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Goal To Reach : Boolean Retreival Model Using Term Document Incedenicnce Matrix\n",
        "\n",
        "# **Steps :**\n",
        "\n",
        "> 1. Handle the Given Collection ( Set Of Documents ) From the user take the unique terms from all of them to be as rows of the term incedeince matrix\n",
        "\n",
        "> 2.  Make the documents as columns of the matrix and encode the appearance of each term inside documents with (1 and 0 )\n",
        "\n",
        "> 3. Take the Query From The User ( Extract the terms from ) , ( Process the boolean operators ) , ( Show the final result )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9sXEsEXkRxbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 ) Handle the collection"
      ],
      "metadata": {
        "id": "rDmRdnkETXEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logical_operators=[\"and\",\"or\",\"not\"]\n",
        "\n",
        "# Correcting the strings\n",
        "'''\n",
        "1) We will define the collection of our documents\n",
        "2) We Will Return list this list will contain the result of unique terms from the whole collection\n",
        "'''\n",
        "\n",
        "def get_unique_terms(data):\n",
        "  results = []\n",
        "  # Iterate through each document (doc here : list corresponding to each key )\n",
        "  for doc in data.values():\n",
        "      # Iterate through each term in the document\n",
        "      for term in doc:\n",
        "          # Check if the term is not already in the results list\n",
        "          if term not in logical_operators:\n",
        "            if term not in results: results.append(term)\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "# Documents\n",
        "d0 = \"English tutorial and fast track\".lower()\n",
        "d1 = \"learning latent semantic indexing\".lower()\n",
        "d2 = \"Book on semantic indexing\".lower()\n",
        "d3 = \"Advance in structure and semantic indexing\".lower()\n",
        "d4 = \"Analysis Analysis of latent structure\".lower()\n",
        "\n",
        "# Dictionary of documents\n",
        "data = {\"d0\": d0.split(), \"d1\": d1.split(), \"d2\": d2.split(), \"d3\": d3.split(), \"d4\": d4.split()}\n",
        "unique_terms=get_unique_terms(data)"
      ],
      "metadata": {
        "id": "Vp2SbFIjRxEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Building the doucment incedience matrix"
      ],
      "metadata": {
        "id": "DMAywCHyYIhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_appearance(collectionDict, target):\n",
        "    #Intiate the list that will contain the encoded result of appearnce the term\n",
        "    result = []\n",
        "    #Looping through collection document searching for the target and fetch on his apperance\n",
        "    for doc in collectionDict.values():\n",
        "        #Encoding Process.....\n",
        "        result.append(1) if target in doc else result.append(0)\n",
        "    return result\n",
        "\n",
        "def building_matrix(unique_terms, data):\n",
        "    #Intiate the desired matrix\n",
        "    matrix = {}\n",
        "    #Loop Through the elments of the extracted unique terms\n",
        "    for term in unique_terms:\n",
        "      #Assign each elment inside the matrix to his corresponding Encoded Matrix\n",
        "        matrix[term] = encode_appearance(data, term)\n",
        "    return matrix\n",
        "\n",
        "def show_the_matrix(matrix):\n",
        "    #Show our Matrix In Much More Readable Way\n",
        "    for key, value in matrix.items():\n",
        "        print(\"{\", key, \"} ->\", value)\n",
        "\n",
        "# Build the term-document incidence matrix\n",
        "term_document_incidence_matrix = building_matrix(unique_terms, data)\n",
        "\n",
        "# Show the term-document incidence matrix\n",
        "show_the_matrix(term_document_incidence_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTQfRPB5aVAP",
        "outputId": "45f778c8-cf76-4d73-9637-71e936bfb04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ english } -> [1, 0, 0, 0, 0]\n",
            "{ tutorial } -> [1, 0, 0, 0, 0]\n",
            "{ fast } -> [1, 0, 0, 0, 0]\n",
            "{ track } -> [1, 0, 0, 0, 0]\n",
            "{ learning } -> [0, 1, 0, 0, 0]\n",
            "{ latent } -> [0, 1, 0, 0, 1]\n",
            "{ semantic } -> [0, 1, 1, 1, 0]\n",
            "{ indexing } -> [0, 1, 1, 1, 0]\n",
            "{ book } -> [0, 0, 1, 0, 0]\n",
            "{ on } -> [0, 0, 1, 0, 0]\n",
            "{ advance } -> [0, 0, 0, 1, 0]\n",
            "{ in } -> [0, 0, 0, 1, 0]\n",
            "{ structure } -> [0, 0, 0, 1, 1]\n",
            "{ analysis } -> [0, 0, 0, 0, 1]\n",
            "{ of } -> [0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Process The Given Query"
      ],
      "metadata": {
        "id": "lvKbikN5lbkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_boolean_query(query, inverted_index):\n",
        "\n",
        "    query_terms = query.split()\n",
        "    results = set(range(len(documents)))\n",
        "\n",
        "    for index in range(len(query_terms)):\n",
        "        term = query_terms[index]\n",
        "\n",
        "        if term == \"AND\":\n",
        "            if index + 1 < len(query_terms):\n",
        "                next_term = query_terms[index + 1]\n",
        "                results = results.intersection(set(inverted_index.get(next_term, [])))\n",
        "\n",
        "        elif term == \"OR\":\n",
        "            if index + 1 < len(query_terms):\n",
        "                next_term = query_terms[index + 1]\n",
        "                results = results.union(set(inverted_index.get(next_term, [])))\n",
        "\n",
        "        elif term == \"NOT\":\n",
        "            if index + 1 < len(query_terms):\n",
        "                next_term = query_terms[index + 1]\n",
        "                results = results.difference(set(inverted_index.get(next_term, [])))\n",
        "\n",
        "        else:\n",
        "            results = results.intersection(set(inverted_index.get(term, [])))\n",
        "\n",
        "    return sorted(list(results))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This iterates through each query, finds matching documents, and then highlights the search terms\n",
        "within those documents.\n",
        "\"\"\"\n",
        "\n",
        "def print_results(queries, documents, inverted_index):\n",
        "\n",
        "    for query in queries:\n",
        "        matching_documents = process_boolean_query(query, inverted_index)\n",
        "\n",
        "        if not matching_documents:\n",
        "            print(f\"Query: {query}, Result: No documents found\")\n",
        "        else:\n",
        "            # Highlight the search terms in the titles of matching documents\n",
        "            emphasized_documents = []\n",
        "            for doc_id in matching_documents:\n",
        "                document = documents[doc_id]\n",
        "                original_query_terms = query.split()\n",
        "               # Replace each word in the document with its bolded version\n",
        "                for term in original_query_terms:\n",
        "                    document = document.replace(term, f\"**{term}**\")\n",
        "                emphasized_documents.append(document)\n",
        "\n",
        "            print(f\"Query: {query}, Result:\")\n",
        "            for doc in emphasized_documents:\n",
        "                print(doc)\n",
        "\n"
      ],
      "metadata": {
        "id": "jzhy6vaYdH_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your collection of documents\n",
        "d0 = \"English tutorial and fast track\".lower()\n",
        "d1 = \"learning latent semantic indexing\".lower()\n",
        "d2 = \"Book on semantic indexing\".lower()\n",
        "d3 = \"Advance in structure and semantic indexing\".lower()\n",
        "d4 = \"Analysis Analysis of latent structure\".lower()\n",
        "\n",
        "# Create a dictionary to hold your documents\n",
        "data = {\"d0\": d0.split(), \"d1\": d1.split(), \"d2\": d2.split(), \"d3\": d3.split(), \"d4\": d4.split()}\n",
        "\n",
        "# Enter your queryquery = input(\"Enter the query here: \").lower()\n",
        "\n",
        "# Retrieve the results using the boolean retrieval function\n",
        "result = boolean_retrieval(query, data)\n",
        "\n",
        "# Print the results\n",
        "print(\"Results:\")\n",
        "for doc, value in result.items():\n",
        "    print(f\"{doc}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "hKCqeTclg3QO",
        "outputId": "76c5a667-0557-40c5-8a12-c78d210cd8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the query here: English and semantic\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'dict' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-20dc57863fa6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Retrieve the results using the boolean retrieval function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboolean_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-886337a38b0e>\u001b[0m in \u001b[0;36mboolean_retrieval\u001b[0;34m(query, collection)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mboolean_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#build a terms_documents incidence matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mterm_docs_incid_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm_document_incidence_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mbitwiseop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#get the query terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgaawsJsg4K7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}